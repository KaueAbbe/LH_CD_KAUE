<h1 align="center"> Bem vinda(o) ao Desafio Cientista de Dadosüòä </h1>

![Badge em Desenvolvimento](https://img.shields.io/static/v1?label=STATUS&message=COMPLETO&color=<COLOR>)

<h1 align ="center"> Objetivo do Caseü§î</h1>

Utilizar conhecimentos de ci√™ncia de dados para compreender o atual contexto de pre√ßos e suas vari√°veis de em um site de loca√ß√£o de im√≥veis. E com isto gerar insights de neg√≥cio e criar um modelo que precifique o valor da loca√ß√£o por noite.  


<h1 align ="center"> Instalando e Executando</h1>

* Para baixar e utilizar o modelo basta seguir os seguintes passo:
  1. Fa√ßa o download dos arquivos: preditor.pkl e pipeline_otimizada.pkl.
  2. Num ambiente virtual python importe a biblioteca pickle e leia o arquivo **preditor**
  3. Fa√ßa a predi√ß√£o do valor passando um dicion√°rio com as seguintes chaves:
     
     {'id': 2595, 'nome': 'Skylit Midtown Castle', 'host_id': 2845, 'host_name': 'Jennifer', 'bairro_group': 'Manhattan', 'bairro': 'Midtown',
 'latitude': 40.75362, 'longitude': -73.98377, 'room_type': 'Entire home/apt', 'minimo_noites': 1, 'numero_de_reviews': 45,
 'ultima_review': '2019-05-21', 'reviews_por_mes': 0.38, 'calculado_host_listings_count': 2, 'disponibilidade_365': 355}

  4. Os valores podem ser alterados.
  5. O valor resultante √© o valor predito pelo modelo


<h1 align ="center"> Resumos das Etapas</h1>

<h2 align ="left"> Tratamento dos Dados</h2>

Realizei tratamento dos dados. Este processo contou as etapas de leitura dos dados, obten√ß√£o de informa√ß√µes b√°sicas do dataset, buscando inconsist√™nicias como valores duplicados e faltantes. Corre√ß√µes foram feitas nas inconsit√™ncias encontradas, criando colunas que informam a exist√™ncia de valores faltantes para levar para An√°lise Explorat√≥ria e para o Modelo de Classifica√ß√£o.

* Leitura, organiza√ß√£o e compreens√£o dos dados.
* An√°lise de tipo de dados.
* Procura e corre√ß√£o das inconsist√™ncias.
* Cria√ß√£o de Novas colunas que informam se os dados eras faltantes.
* Avaliar e retirar duplicatas.
* Cria√ß√£o de novo arquivo para uso futuro.

<h2 align ="left"> An√°lise Explorat√≥ria e Explanat√≥ria</h2>

Realizei an√°lise estat√≠stica descritiva univariadas. Realizei an√°lise bivariada, analisando a rela√ß√£o das featues com o pre√ßo, realizando nesta etapa estat√≠stica inferencial com uso de teste de hip√≥teses n√£o param√©tricos. Com as informa√ß√µes adquiridas realizei data visualization, e utilizei modelos para ajudar a compreender o papel de cada feature com rela√ß√£o a target(pre√ßo). Apliquei **t√©cnicas de NLP** e visualizei o padr√£o de nomes de loca√ß√µes para altos pre√ßos e baixos pre√ßos. Com base nestas informa√ß√µes criei hip√≥teses e sugest√µes de neg√≥cios. 

* An√°lise da vari√°vel target, visualiza√ß√£o de distribui√ß√£o
* An√°lise de dados qualitativos e quantitativos
* An√°lise bivariada entre grupos da vari√°vel target
* Data visualization
* Testes de hip√≥teses
* Storytelling
* Cria√ß√£o e teste de regra de Bussines
* T√©cnicas de NLP
  
<h3 align ="left"> Informa√ß√µes Descobertas e Respondendo Perguntas</h3>

Abaixo apresento gr√°ficos que mostram a m√©dia de valores separados em grupos de bairros e grupos de tipo de loca√ß√£o.

![preco_bairro2](https://github.com/KaueAbbe/LH_CD_KAUE/assets/68445400/204769ff-9cf7-451c-b6c9-d2a7e1ffc117)

O bairro que possui valor m√©dio maior √© Manhattan, no entanto n√£o diferen√ßa estat√≠stica entre os bairos Manhattan, Brooklyn e Staten Island.

![tipos](https://github.com/KaueAbbe/LH_CD_KAUE/assets/68445400/f566c2b1-cf59-4e17-ac21-4d49d08aba17)

Enquanto os tipos de loca√ß√µes, a com maior pre√ßo m√©dio √© a casa inteira / Apartamento. 

Por an√°lises obtive a seguinte conclus√£o:

1. A falta de nome do apto e do host diminui o valor m√©dio.
2. A falta de review aumenta o valor m√©dio.

E baseado nos gr√°ficos e nas an√°lises criei as seguintes sugest√µes de neg√≥cio:

1. Podemos selecionar apartamentos que est√£o sem review, e sugerir ao host que abaixe o pre√ßo abaixo para aumentar a chance de loca√ß√£o.
2. Podemos adicionar alertas aos hosts para adicionar seus nomes ao apartamento, informando que assim agrega mais valor.
3. Podemos adicionar alertas aos hosts para adicionar nomes aos quartos, al√©m de criar dar sugest√µes baseadas em outros quartos.
   
<h4 align ="left"> Melhor indica√ß√£o de Compra de Apartamento</h4>

* Definindo como condi√ß√£o de melhor loca√ß√£o: ter pre√ßo m√©dio e ter reviews.
  Tal decis√£o foi tomada pois assim a pessoa pode ter um lugar acess√≠vel financeiramente, e que pode obter informa√ß√µes sobre a loca√ß√£o por meio de outras pessoas.
  
* Baseando que a pessoa quer o melhor local para alugar, considerei que melhor o local com maior n√∫mero de reviews e com grupo de bairro de pre√ßo m√©dio. O lugar √©: **Staten Island, no bairro de Silver Lake**. O pre√ßo m√©dio √© de $173, e possui 147 reviews.

<h4 align ="left"> O n√∫mero m√≠nimo de noites e a disponibilidade ao longo do ano interferem no pre√ßo?</h4>

*Apresento dois gr√°ficos



![preco_noite](https://github.com/KaueAbbe/LH_CD_KAUE/assets/68445400/dd0e2d74-11ba-45e3-8b94-8297d682a700)


O gr√°fico acima apresenta um aglomerado de valores com baixo pre√ßo e baixo n√∫mero de m√≠nimo de noites. E apresenta valores discrepantes com altos pre√ßos e baixo valor m√≠nimo de noite, com poucos valores de baixo pre√ßo e alto valor m√≠nimo de noite. 

![preco_disp](https://github.com/KaueAbbe/LH_CD_KAUE/assets/68445400/f717e377-c8e2-478c-a26a-5f745f71a08e)

O gr√°fico apresenta valores espalhados pelo gr√°fico, sem apresentar nenhuma tend√™ncia.

Calculei tamb√©m qual o tamanho da interfer√™ncia entre os dois valores: Ambas tiveram valores muito baixos. 


* Portanto baseando nos gr√°ficos e nos valores de correla√ß√£o entre pre√ßo e vari√°veis, conclui-se que o **tempo m√≠nimo de noites e a disponibilidade n√£o tem interfer√™ncia significativa no pre√ßo.**

  

  <h4 align ="left"> Padr√£o no nome de loca√ß√µes acima da m√©dia</h4>
  
* Analisando as palavras mais usadas para loca√ß√µes acima da m√©dia obtive a seguinte nuvem de palavras e resultados comparativos:
* 
![word_cloud_alto](https://github.com/KaueAbbe/LH_CD_KAUE/assets/68445400/f03f8953-52f4-4868-924a-a7cf2b537b4e)

* Os resultados comparativos indicam:
  1. Existem palavras que repetem tanto abaixo da m√©dia quanto acima: *Apartment, Bedroom,apt, studio, spacius*.
  2. As **palavras iguais s√£o menos frequentes no grupo acima da m√©dia**. E os acima da m√©dia n√£o utilizam muito a palavra room.
  3. O grupo abaixo da m√©dia utiliza palavras da localiza√ß√£o: Brooklyn e Manhattan. 
  4. √â mais comum ao grupo acima da m√©dia utilizar numerais no texto.

Baseados nesses dados fa√ßo duas sugest√µes:
1. Criar um painel de dicas para o host quando for criar o nome da loca√ß√£o, sugerindo, por exemplo, n√£o utilizar nomes de localiza√ß√£o.
2. Realizar uma an√°lises aprofundade apenas nos textos para avaliar se a utiliza√ß√£o (ou a falta) de determinadas palavras se deve ao tipo de loca√ß√£o e se resultado em melhores resultados na loca√ß√£o.



 
<h2 align ="left"> Cria√ß√£o do Modelo</h2>

* Tal modelo tem objetivo de precificar loca√ß√µes, portanto se trata de um modelo de regress√£o.

  Esta cria√ß√£o de modelo seguiu os seguintes passos:
  1. Importa√ß√£o de M√≥dulos de bibliotecas necess√°rios.
  2. Escolha da m√©trica: R¬≤ - r2_score -> Escolhi esta m√©trica pois analisa a dist√¢ncia entre o valor predito e real, possuindo f√°cil interpreta√ß√£o.
     
  3. Prepara√ß√£o dos dados:
     * Foram retirados os valores outliers, j√° que modelos de regress√£o s√£o sens√≠veis a outliers e podem resultar em baixo poder de predi√ß√£o.
     * Separa√ß√£o dos dados em treino, teste e valida√ß√£o: Ser√£o usados para, respectivamente, treinar, testar o modelo e validar o resulto p√≥s otimiza√ß√£o. Esta t√©cnica evita com que haj√° vi√©s e vazamento de dados no modelo, garantindo que posso avaliar seu ajuste aos dados e poder de predi√ß√£o.
     * Obten√ß√£o das features com alta cardinalidade, salvando seus nomes. Estas features ser√£o retiradas dos dados de treino por n√£o agregar √† generaliza√ß√£o do modelo.
     * Cria√ß√£o de lista de features categ√≥ricas que ter√£o tratamento por T√©cnicas de Encoding.
  
  4. Cria√ß√£o da Pipeline de Treino com seguintes passos:
     * Receber os dados de treino e teste.
     * Retirar as colunas com alta cardinalidade.
     * Aplicar Target Encoding em features espec√≠ficas: Esta t√©cnica transforma valores categ√≥ricos em n√∫mericos baseando no target, colocando um valor esperando. Esta t√©cnica foi utilizando em apenas features bastantes valores √∫nicos.
     * Aplicar OneHotEncoding na feature bairro_group: Esta t√©cnica cria quantidade de colunas igual a quantidade de cardinalidade na feature original, onde cada nova colunas informa com 0 ou 1 se a loca√ß√£o √© de tal bairro ou n√£o. Utilizei essa t√©cnica apenas em feature com baixa cardinalidade.
     * Aplica√ß√£o do MinMaxScaler: Usado para reorganizar os valores dos dados cont√≠nuos entre 0 e 1, para auxiliar na melhor performance dos modelos. O uso deste Scaler √© porque os dados n√£o seguem distribui√ß√£o normal.
     * Treinamento do modelo utilizando valida√ß√£o cruzada: O uso da valida√ß√£o cruzada foi para realizar mais de um treinamento com split dos dados de treino, obtendo um valor m√©dio da m√©trica escolhida.
     * Fazer um predict com dados de teste e avaliar a perfomace: Com este valor observo se os resultados de treino e teste est√£o discrepantes, assim indicando overfitting ou underfitting.

  5. Otimiza√ß√£o de Hiper Par√¢metros do melhor modelo:
     * O melhor modelo escolhido teve que apresentar a melhor perfomance no treino e no teste. Al√©m de n√£o apresentar overfitting nem underfitting, pois assim garanto que o modelo est√° tenho boa performance e generaliza√ß√£o.
     * Tamb√©m foi levado em considera√ß√£o o tempo de treino do modelo, medido de forma heur√≠stica. Isto porque √© importante que o modelo tamb√©m possa trazer resultados mais r√°pidos.
     * A otimiza√ß√£o foi feita utilizando RandomizedSearchCV e GridSearchCV: O Randomized foi utilizado para otimizar por ser mais r√°pido que o GridSearch, no entanto tamb√©m utilizei o GridSearch com menos entradas para poder fazer uma busca mais vasta dentro das combina√ß√µes poss√≠veis de hiper par√¢metros.

    6. Cria√ß√£o da Pipeline com Modelo Otimizado
       * Com o resultado da melhor combina√ß√£o de hiperpar√¢metros, criei a pipelina seguinte as mesma especifica√ß√µes da pipeline de treino, alterando apenas o modelo para ter os hiperpar√¢metros encontrados.
       * Realizei o teste do modelo final com os dados de valida√ß√£o: O uso dos dados de valida√ß√£o serve para avaliar o desempenho do modelo com dados nunca vistos.
    7. Cria√ß√£o de uma fun√ß√£o preditora:
       * A fun√ß√£o preditora foi criada pois o treino do modelo possuia dados criados durante tratamento, e que n√£o ser√£o passados quando ocorrer um predi√ß√£o com novos dados.
       * A fun√ß√£o adicionar os dados novos: S√£o basicamentos dados missing de determinadas colunas
       * A fun√ß√£o remover colunas que n√£o foram usadas no treinamento: as de alta cardinalidade.
       * A fun√ß√£o l√™ o arquivo Pickle da pipeline otimizada e retorna a predi√ß√£o.
    8. Salvamento da pipeline otimizada e da fun√ß√£o em formato pkl para ser disponibilidade para um futuro deploy e usada em predi√ß√µes de novos dados. 


  

  
<h3 align ="left"> Resultados Modelo </h3>

O modelo utilizado foi: HistGradientBoostingRegressor, pelos seguintes motivos:
* O modelo √© do tipo Ensemble, que utiliza v√°rios algoritmos que melhora a generaliza√ß√£o e robustez.
* O modelo performa mais r√°pido que o GradientBoostingRegressor, que √© um "irm√£o" do modelo.
* O modelo apresentou rapidez e desempenho melhor, tanto no treino como no teste.
* **Ap√≥s otimiza√ß√£o:** O modelo apresentou R¬≤ = 70%. Isto mostra que o modelo possui boa generaliza√ß√£o dos dados, e tem bom poder de predi√ß√£o.

1. Com os dados dados pelo desafio (dicion√°rio escrito na etapa de instala√ß√£o e execu√ß√£o deste readme) **o resultado obtido pelo preditor foi: $ 192.99**.


<h2 align ="center"> Pr√≥ximas Etapas</h2>

Os resultados finais apresentados foram obtidos com dados de valida√ß√£o do modelos, o que mostra que o modelo perfomaria bem no dia a dia. O pr√≥ximo passo seria fazer o deploy do modelo, para ser utilizado pela empresa. Al√©m disto, deveria ser estabelecer formas acompanhar o desempenho do modelo com o tempo. Outras etapas s√£o avaliar e projetar as sugest√µes dados neste relat√≥rio, passando aos times necess√°rios. 

<h2 align ="center">Autor üöÄ</h2>
<a>
<img style = "border-radius: 50%;" src = https://github.com/KaueAbbe/Analise_ChurnRate/assets/68445400/bd4b5b79-4826-4d72-91e4-5fc7532ac19b width="250px;" alt=""/>

 <sub><b></b></sub></a> 

<h4> Feito com üíô por Kaue Hermann Abbehausen üëãüèΩ 
<br/> 
 
 1.Cientista de Dados
 
 2. Formado em F√≠sica na Universidade Federal de Uberl√¢ndia
 
 3. Mestre em F√≠sica Estat√≠stica na Universidade de Bras√≠lia</h4>
<h4> Entre em contato por</h4>
<div align = "center"> 

<div align = "center"> 
   <a href="https://www.linkedin.com/in/kaue-abbehausen-5b1922165/" target="_blank"><img src="https://img.shields.io/badge/-LinkedIn-%230077B5?style=for-the-badge&logo=linkedin&logoColor=white" target="_blank"></a> 
  <a href="https://www.instagram.com/kaue.hermann/" target="_blank"><img src="https://img.shields.io/badge/-Instagram-%23E4405F?style=for-the-badge&logo=instagram&logoColor=white" target="_blank"></a>
  <a href = "mailto:kaueabbehausen@gmail.com"><img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white"></a>
</div>
